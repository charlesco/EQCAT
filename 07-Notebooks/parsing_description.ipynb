{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture des fichiers j-shis \n",
    "Se référer au file format specification sur le site de j-shis (http://www.j-shis.bosai.go.jp/map/JSHIS2/data/DOC/DataFileRule/A-RULES_en.pdf)\n",
    "Lecture dans l'ordre de :\n",
    "- Parameters for seismic activity evaluation and Fault shape of EarthQuake’s Traces Hardly Recognized (EQTHR) from surface evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des packages\n",
    "#packages basiques\n",
    "import re\n",
    "import pandas as pd\n",
    "#packages persos\n",
    "from earthquake import SegmentEarthquake, MultiSegmentEarthquake, PointsEarthquake, MultiPointsEarthquake,\\\n",
    "    DomainEarthquake, ZoneEarthquake\n",
    "from shape import PlaneShape, MultiPlaneShape, PointShape, MultiPointShape\n",
    "from magnitude import GutenbergRichter, CharacteristicMag, DiscreteMagnitude\n",
    "from occurrence import PoissonProcess, BrownianPTProcess, YearFreqProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters for seismic activity evaluation and Fault shape of EarthQuake’s Traces Hardly Recognized (EQTHR) from surface evidences (P-Y2017-PRM_MAX_LND_A98F_EQTHR_EN.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fichier en blocs décrivant chacun une source de séisme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une première ligne décrivant la loi de gutemberg richter doublement tronquée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column | Explanation               |\n",
    "|-----------------------------------------|\n",
    "| 01 | Fault code                        |\n",
    "| 02 | Mean recurrence interval (Years) |\n",
    "| 03 | The minimum magnitude          |\n",
    "| 04 | The maximum magnitude          |\n",
    "| 05 | b-value                        |\n",
    "| 06 | Number of fault planes           |\n",
    "| 07 | Fault name                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis une série de lignes décrivant chacune un des rectangles composant la surface de rupture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column | Explanation                                                                          |\n",
    "|--------|--------------------------------------------------------------------------------------|\n",
    "| 01     | Rectangular fault number                                                             |\n",
    "| 02     | Longitude of the reference point of rectangular fault (Tokyo datum)                  |\n",
    "| 03     | Latitude of the reference point of rectangular fault (Tokyo datum)                   |\n",
    "| 04     | Longitude of the reference point of rectangular fault (Japanese Geodetic Datum 2000) |\n",
    "| 05     | Latitude of the reference point of rectangular fault (Japanese Geodetic Datum 2000)  |\n",
    "| 06     | Depth of the upper edge of rectangular fault (km)                                    |\n",
    "| 07     | Length of rectangular fault (km)                                                     |\n",
    "| 08     | Width of rectangular fault (km)                                                      |\n",
    "| 09     | Strike angle (degree)                                                                |\n",
    "| 10     | Dip angle (degree)                                                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrait:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| F004501 | 12800   | 6.8    | 7.4     | 0.9    | 2 | Kiso-sanmyaku-seien fault zone (Main part/Northern segment) |    |      |    |\n",
    "|---------|---------|--------|---------|--------|---|-------------------------------------------------------------|----|------|----|\n",
    "| 1       | 137.603 | 35.58  | 137.6   | 35.583 | 2 | 14                                                          | 16 | 44.4 | 90 |\n",
    "| 2       | 137.728 | 35.673 | 137.725 | 35.676 | 2 | 30                                                          | 18 | 20.6 | 40 |\n",
    "| F004502 | 9000    | 6.3    | 6.3     | 0.9    | 1 | Kiso-sanmyaku-seien fault zone (Main part/Southern segment) |    |      |    |\n",
    "| 1       | 137.586 | 35.514 | 137.583 | 35.517 | 2 | 9.4                                                         | 9  | 9.3  | 90 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui regroupe le numéros des lignes qui commencent par une lettre dans une liste\n",
    "\n",
    "def detect_blocks(data):\n",
    "    start_lines = []\n",
    "    for i, line in enumerate(data):\n",
    "        if re.search(r'[A-Z]', line):\n",
    "            start_lines += [i]\n",
    "    return start_lines\n",
    "\n",
    "\n",
    "#Lecture d'une première ligne de bloc décrivant la loi de magnitude\n",
    "#Création d'une loi de gutemberg richter doublement tronquée (voir GutenbergRichter) associée au code de la source\n",
    "\n",
    "def parse_fault_info(line):\n",
    "    flt_info = line.split(',')\n",
    "    eq_code = flt_info[0]\n",
    "    # On ne retient pas la période de retour car une information plus riche sur la loi de survenance de la source est disponible ailleurs\n",
    "    # avract = float(flt_info[1])\n",
    "    min_mag = float(flt_info[2])\n",
    "    max_mag = float(flt_info[3])\n",
    "    b_val = float(flt_info[4])\n",
    "    nb_planes = int(flt_info[5])\n",
    "    name = flt_info[6]\n",
    "    if max_mag > min_mag:\n",
    "        mag = GutenbergRichter(min_mag, b_val, max_mag)\n",
    "    else:\n",
    "        mag = CharacteristicMag(min_mag)\n",
    "    return eq_code, mag, nb_planes, name\n",
    "\n",
    "#Lecture d'une ligne décrivant un rectangle\n",
    "#Création d'un rectangle (voir PlaneShape)\n",
    "\n",
    "def parse_plane_info(line):\n",
    "    pln_info = line.split(',')\n",
    "    idx = int(pln_info[0])\n",
    "    lon = float(pln_info[3])\n",
    "    lat = float(pln_info[4])\n",
    "    dep = float(pln_info[5])\n",
    "    leng = float(pln_info[6])\n",
    "    wid = float(pln_info[7])\n",
    "    strike = float(pln_info[8])\n",
    "    dip = float(pln_info[9])\n",
    "    plane = PlaneShape(idx, lon, lat, dep, leng, wid, strike, dip)\n",
    "    return plane\n",
    "\n",
    "\n",
    "#Lecture du fichier\n",
    "#Création d'un ensemble de plans (voir MultiPlaneShape)\n",
    "\n",
    "def parse_eqthr(quakes):\n",
    "    fil = open('hazard_inputs/P-Y2017-PRM_MAX_LND_A98F_EQTHR_EN.csv')\n",
    "    data = fil.readlines()[5:]\n",
    "    #Liste des débuts de blocs\n",
    "    start_lines = detect_blocks(data)\n",
    "    for i in start_lines:\n",
    "        #Lecture de la première ligne du bloc décrivant la magnitude\n",
    "        eq_code, mag, nb_planes, name = parse_fault_info(data[i])\n",
    "        plane_list = []\n",
    "        for j in range(nb_planes):\n",
    "            #Lecture d'une ligne décrivant un plan\n",
    "            plane = parse_plane_info(data[i + j + 1])\n",
    "            plane_list += [plane]\n",
    "        shape = MultiPlaneShape(plane_list)\n",
    "        quakes[eq_code] = {'code': eq_code, 'mag': mag, 'shape': shape, 'name': name}\n",
    "    fil.close()\n",
    "    return quakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters for seismic activity evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Earthquake type | File name                         |\n",
    "|---------------------------------------------------|\n",
    "| Parameters for seismic activity evaluation of Characteristic earthquakes occurring in major active fault zones (Maximum case) | P-2017-ACT_MAX_LND_A98F_EN.csv|\n",
    "| Parameters for seismic activity evaluation of subduction-zone earthquakes (Maximum case)| P-2017 -PRM-ACT_MAX_PME_MTTL_EN.csv |\n",
    "| Parameters for seismic activity evaluation of Earthquakes occurring on active faults other than major active fault zones | P-2017-PRM-ACT_AVR_LND_AGR1_EN.csv |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces 3 fichiers se présentent au même format et peuvent être lus comme des dataframes\n",
    "\n",
    "Ils décrivent la loi de survenance d'une grande partie des sources\n",
    "\n",
    "Chaque ligne décrit la loi de survenance d'une source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column | Explanation                                                                                                                                                                                                                                            |\n",
    "|--------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| CODE   | Fault code                                                                                                                                                                                                                                             |\n",
    "| PROC   | Stochastic process (BPT: BPT processes, POI: Poisson process, COM: Combined BPT and POI, BSI: BPT process (Simultaneous occurring model), PSI: Poisson process (Simultaneous occurring model),SIM: Simultaneous occurring model, XXX: None evaluation) |\n",
    "| AVRACT | Mean recurrence interval (Years)                                                                                                                                                                                                                       |\n",
    "| NEWACT | The time of the latest event (Years ago: from reference date)                                                                                                                                                                                          |\n",
    "| ALPHA  | Variance                                                                                                                                                                                                                                               |\n",
    "| P_T30  | Probability of occurrence in 30 years                                                                                                                                                                                                                  |\n",
    "| P_T50  | Probability of occurrence in 50 years                                                                                                                                                                                                                  |\n",
    "| NAME   | Fault name                                                                                                                                                                                                                                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lecture des fichiers d'activité\n",
    "#Création des lois de survenance (voir PoissonProcess et BrownianPTProcess)\n",
    "def parse_activity(quakes):\n",
    "    #Lecture des fichiers\n",
    "    activity = pd.read_csv('hazard_inputs/P-Y2017-PRM-ACT_MAX_LND_A98F_EN.csv', skiprows=8, skipinitialspace=True,\n",
    "                           index_col=0)\n",
    "    activity2 = pd.read_csv('hazard_inputs/P-Y2017-PRM-ACT_AVR_LND_AGR1_EN.csv', skiprows=8, skipinitialspace=True,\n",
    "                            index_col=0)\n",
    "    activity = activity.append(activity2)\n",
    "    activity2 = pd.read_csv('hazard_inputs/P-Y2017-PRM-ACT_MAX_PME_MTTL_EN.csv', skiprows=8, skipinitialspace=True,\n",
    "                            index_col=0)\n",
    "    activity = activity.append(activity2)\n",
    "    for eq_code, row in activity.iterrows():\n",
    "        #Processus de Poisson: un paramètre\n",
    "        if row['PROC'] in ['POI', 'PSI'] and row['AVRACT'] != '-':\n",
    "            process = PoissonProcess(row['AVRACT'])\n",
    "        #Temps de premier passage: 3 paramètres\n",
    "        elif row['PROC'] in ['BPT', 'BSI', 'COM']:\n",
    "            process = BrownianPTProcess(row['AVRACT'], row['NEWACT'], row['ALPHA'])\n",
    "        else:\n",
    "            process = ''\n",
    "        dico = {'process': process}\n",
    "        if eq_code in quakes:\n",
    "            quakes[eq_code].update(dico)\n",
    "        else:\n",
    "            dico.update({'code': eq_code, 'name': row['NAME']})\n",
    "            quakes[eq_code] = dico\n",
    "    return quakes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### MultiActivity File (MultiActivity.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture des sources étant la réunion de plusieurs sources\n",
    "\n",
    "On trouve le code, le nom de la source et la liste des codes des sources qu'elle réunit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| CODE    | NAME                                                        | SEGMENTS                |\n",
    "|---------|-------------------------------------------------------------|-------------------------|\n",
    "| F01220B | Nishiyama fault zone (Oshima-Oki segment/Nishiyama segment) | F012201;F012202         |\n",
    "| F01220C | Nishiyama fault zone (Nishiyama segment/Kama-toge segment)  | F012202;F012203         |\n",
    "| F01220A | Nishiyama fault zone (All segment)                          | F012201;F012202;F012203 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_multi(quakes):\n",
    "    df = pd.read_csv('hazard_inputs/MultiActivity.csv', index_col=0)\n",
    "    for code, row in df.iterrows():\n",
    "        quakes[code]['segments'] = row['SEGMENTS'].split(';')\n",
    "        quakes[code]['process'] = 'multi'\n",
    "    return quakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_frequencies(quakes):\n",
    "    codes1 = ['LND_CGR5_CRUST', 'LND_CIZU_CRUST', 'LND_CJPS_CRUST', 'PSE_CURA_CRUST']\n",
    "    codes2 = ['PSE_CPCF_INTER', 'PSE_CPCF_INTRA', 'PSE_CPHL_INTER', 'PSE_CPHL_INTRA']\n",
    "    for code in codes1:\n",
    "        file_name = 'hazard_inputs/P-Y2017-PRM-ACT_' + code + '_CV_SM.csv'\n",
    "        df = pd.read_csv(file_name, skiprows=7, skipinitialspace=True)\n",
    "        l = code.split('_')\n",
    "        code, typ = l[1], l[2]\n",
    "        eqtype = {'CRUST': 1, 'INTER': 2, 'INTRA': 3}[typ]\n",
    "        for _, row in df.iterrows():\n",
    "            if row['FRQ'] > 0:\n",
    "                process = YearFreqProcess(row['FRQ'])\n",
    "                mag = GutenbergRichter(row['MMN'], row['BVL'])\n",
    "                shape = PointShape(row['# MNO'], row['WLG'], row['WLA'], row['DEP'])  # , row['STR'], row['DIP']\n",
    "                code3 = code + '_' + str(int(row['ANO'])) + '_' + str(int(row['# MNO']))\n",
    "                quakes[code3] = {'code': code3, 'name': code3, 'process': process, 'mag': mag, 'shape': shape,\n",
    "                                 'eqtype': eqtype}\n",
    "    for code in codes2:\n",
    "        file_name = 'hazard_inputs/P-Y2017-PRM-ACT_' + code + '_CV_SM.csv'\n",
    "        df = pd.read_csv(file_name, skiprows=7, skipinitialspace=True)\n",
    "        l = code.split('_')\n",
    "        code, typ = l[1] + '_' + l[2], l[2]\n",
    "        eqtype = {'CRUST': 1, 'INTER': 2, 'INTRA': 3}[typ]\n",
    "        for _, row in df.iterrows():\n",
    "            if row['FRQ'] > 0:\n",
    "                process = YearFreqProcess(row['FRQ'])\n",
    "                mag = GutenbergRichter(row['MMN'], row['BVL'])\n",
    "                shape = PointShape(row['# MNO'], row['WLG'], row['WLA'], row['DEP'])  # , row['STR'], row['DIP']\n",
    "                code3 = code + '_' + str(int(row['ANO'])) + '_' + str(int(row['# MNO']))\n",
    "                quakes[code3] = {'code': code3, 'name': code3, 'process': process, 'mag': mag, 'shape': shape,\n",
    "                                 'eqtype': eqtype}\n",
    "    return quakes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
